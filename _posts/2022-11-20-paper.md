---
layout: post
title: "論文メモ -Adversarial Fraud Generation for Improved Detection-"
---

必要にせまられて[この論文](https://dl.acm.org/doi/abs/10.1145/3533271.3561723)読み始めた。
ICAIFはどうやら2020年からはじまったまだ幼い国際会議っぽい。

# ABSTRACT
* class inbalanceなデータに対してGANを用いてオーバーサンプリングする手法が知られている。
  * しかし既存研究手法は少数クラスの代表的なサンプルに近似したデータをオーバーサンプリングしがちで多様性がない課題がある。
* 本論文では正常な取引に条件付けられた決定境界付近の不正な取引をGANを使って再現する手法を提案。
  * Generatorの損失関数に学習データ汚染攻撃の文脈を取り入れる。
* European Credit-Card DatasetとCIS Fraud Datasetを用いて上記手法の有効性を示す。

# INTRODUCTION
* class imbalanceに対するオーバーサンプリング手法として代表的なものに[SMOTE](https://www.jair.org/index.php/jair/article/view/10302)がある。
  * この[Qiitaの記事](https://qiita.com/eigs/items/8ae0970afe188a1124d1)でSMOTEをなんとなく理解。
  * 非常にサンプルな手法だけど、線形補間を使った手法なので非線形性を持つ複雑なデータにはアンマッチ。
* 最近はDLベースの生成モデルがオーバーサンプリング手法として活発に研究されている。
  * だけど、本論文ではそういった手法(GANベース)には課題があるとしている。
    * (1) 不正クラスの分布の表現に失敗している。一般的に多く起こる不正パターンに近似された不正パターンばかりを多くの生成モデルが生成。
    * (2) 偽陽性を検知しがち。つまり、正常な取引を不正なものと誤分類しがち。
* 本論文では正常な取引に条件付けられたGANを使って不正パターンを生成する。
    
# RELATED WORKS
* 教師あり学習手法でclass imbalanceな問題に対処するためには2つの方法が存在する。
  * (1) アンダーサンプリング
  * (2) オーバーサンプリング
* アンダーサンプリングは本質的な情報を失うかもしれないので望ましくない。
* 一番ナイーブなオーバーサンプリング手法は少数派クラスのサンプルのコピー。
  * これは新しい情報を付加しないので、分類器の汎化性能の向上には限界あり。
* 次に[SMOTE](https://arxiv.org/pdf/1106.1813.pdf)を使って少数派クラスを生成する手法が登場。
  * これは既存のデータで内挿を用いてデータ生成を行うため、未知のサンプルを生成する機能が制限される。
* 近年は深層生成モデルを用いたクレジットカード不正検知の研究が大きな注目を集めている。
  * いくつかのGANを用いたデータ拡張の手法が有効性を示しているが、モード崩壊の問題を抱えている。
  * この問題を解決するためにWGANベースの手法が用いられ、分類精度の向上が確認されている。

# METHODOLOGY
* ネットワークの根幹はWCGAN-GP。
  * 既存のGANベースの手法は、一般的な不正パターンを生成し、不正データ空間表現の獲得に失敗していた。
  * そこで本手法では、学習データ汚染攻撃の文脈で使われる[Feature Collision Attack](https://proceedings.neurips.cc/paper/2018/file/22722a343513ed45f14905eb07621686-Paper.pdf)と[Convex Polytope Attack](https://arxiv.org/pdf/1905.05897.pdf)で利用してデータ生成過程を正規化する。
    * この2つの手法の解説は[ここ](https://jpsec.ai/attack-to-hijack-ai/)が辿っていくとなんとなく分かった気になれる。
    * Convex Polytope Attackのc(Convex combination coefficient)をどうやって決めるのか論文のどこにも言及がない・・・。
  * Generatorの損失関数にこの2つの手法に着想を得た損失項を加える。
    * あとは普通にbackpropで最適化していくっぽい。ちょっと乱暴では...?

　
# EXPERIMENTS
* [European Credit-Card Dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud)と[CIS Fraud Dataset](https://www.kaggle.com/c/ieee-fraud-detection)を用いて有効性を検証。
  * CIS Fraud Datasetのほうが精度低くて、何故こんなに差が有るのか気になる。
  * 学習データ：検証データ：テストデータは7:1:2で分割。
* Pytorchで実装。GeneratorとDiscriminatorは4層NN。論文中のハイパラはなぜその数字にしたのか言及なし。
* 結果としては2つのデータセットにおいて、提案手法がSOTAなF1値を達成。
* SMOTEを用いた場合、オーバーサンプリングなしと比べて精度落ちてる。
* 提案手法でオーバーサンプリングした特徴量を2次元空間上にマップしたものを見ると、確かに分散して生成されてるように見える。
  * どうやって2次元空間上にマップしたのかは言及なし・・・。
* データセットによって最適なオーバーサンプリング数は異なる。ここをどうやって決めるべきはFuture work。(だれか研究しろってことぽい)


# CONCLUSION
* 既存研究は少数クラスの代表的なサンプルに近似したサンプルを生成しがち。
* 提案手法は学習データ汚染攻撃から着想を得た新しいGeneratorの損失関数を提案し、精度の観点で一定の有効性を示した。




  

